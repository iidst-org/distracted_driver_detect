{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import layers\n",
    "from keras.layers import (Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, \n",
    "                          Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D)\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from resnets_utils import *\n",
    "from keras.initializers import glorot_uniform\n",
    "import scipy.misc\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate, LeaveOneGroupOut\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotClassFrequency(class_counts):\n",
    "    plt.figure(figsize=(15,4))\n",
    "    plt.bar(class_counts.index,class_counts)\n",
    "    plt.xlabel('class')\n",
    "    plt.xticks(np.arange(0, 10, 1.0))\n",
    "    plt.ylabel('count')\n",
    "    plt.title('Number of Images per Class')\n",
    "    plt.show()\n",
    "\n",
    "def DescribeImageData(data):\n",
    "    print('Average number of images: ' + str(np.mean(data)))\n",
    "    print(\"Lowest image count: {}. At: {}\".format(data.min(), data.idxmin()))\n",
    "    print(\"Highest image count: {}. At: {}\".format(data.max(), data.idxmax()))\n",
    "    print(data.describe())\n",
    "    \n",
    "def CreateImgArray(height, width, channel, data, folder, save_labels = True):\n",
    "    \"\"\"\n",
    "    Writes image files found in 'imgs/train' to array of shape\n",
    "    [examples, height, width, channel]\n",
    "    \n",
    "    Arguments:\n",
    "    height -- integer, height in pixels\n",
    "    width --  integer, width in pixels\n",
    "    channel -- integer, number of channels (or dimensions) for image (3 for RGB)\n",
    "    data -- dataframe, containing associated image properties, such as:\n",
    "            subject -> string, alpha-numeric code of participant in image\n",
    "            classname -> string, the class name i.e. 'c0', 'c1', etc. \n",
    "            img -> string, image name\n",
    "    folder -- string, either 'test' or 'train' folder containing the images\n",
    "    save_labels -- bool, True if labels should be saved, or False (just save 'X' images array).  \n",
    "                   Note: only applies if using train folder\n",
    "            \n",
    "    Returns:\n",
    "    .npy file -- file, contains the associated conversion of images to numerical values for processing\n",
    "    \"\"\"\n",
    "    \n",
    "    num_examples = len(data)\n",
    "    X = np.zeros((num_examples,height,width,channel))\n",
    "    if (folder == 'train') & (save_labels == True):\n",
    "        Y = np.zeros(num_examples)\n",
    "    \n",
    "    for m in range(num_examples):\n",
    "        current_img = data.img[m]\n",
    "        img_path = 'imgs/' + folder + '/' + current_img\n",
    "        img = image.load_img(img_path, target_size=(height, width))\n",
    "        x = image.img_to_array(img)\n",
    "        x = preprocess_input(x)\n",
    "        X[m] = x\n",
    "        if (folder == 'train') & (save_labels == True):\n",
    "            Y[m] = data.loc[data['img'] == current_img, 'classname'].iloc[0]\n",
    "        \n",
    "    np.save('X_'+ folder + '_' + str(height) + '_' + str(width), X)\n",
    "    if (folder == 'train') & (save_labels == True):\n",
    "        np.save('Y_'+ folder + '_' + str(height) + '_' + str(width), Y)\n",
    "        \n",
    "def Rescale(X):\n",
    "    return (1/(2*np.max(X))) * X + 0.5\n",
    "\n",
    "def PrintImage(X_scaled, index, Y = None):\n",
    "    plt.imshow(X_scaled[index])\n",
    "    if Y is not None:\n",
    "        if Y.shape[1] == 1:\n",
    "            print (\"y = \" + str(np.squeeze(Y[index])))\n",
    "        else:\n",
    "            print(\"y = \" + str(np.argmax(Y[index])))\n",
    "            \n",
    "def LOGO(X, Y, group, model_name, input_shape, classes, init, optimizer, metrics, epochs, batch_size):\n",
    "    logo = LeaveOneGroupOut()\n",
    "    logo.get_n_splits(X, Y, group);\n",
    "    cvscores = np.zeros((26,4))\n",
    "    subject_id = []\n",
    "    i = 0\n",
    "    for train, test in logo.split(X, Y, group):\n",
    "        # Create model\n",
    "        model = model_name(input_shape = input_shape, classes = classes, init = init)\n",
    "        # Compile the model\n",
    "        model.compile(optimizer = optimizer, loss='sparse_categorical_crossentropy', metrics=[metrics])\n",
    "        # Fit the model\n",
    "        model.fit(X[train], Y[train], epochs = epochs, batch_size = batch_size, verbose = 0)\n",
    "        # Evaluate the model\n",
    "        scores_train = model.evaluate(X[train], Y[train], verbose = 0)\n",
    "        scores_test = model.evaluate(X[test], Y[test], verbose = 0)\n",
    "        # Save to cvscores\n",
    "        cvscores[i] = [scores_train[0], scores_train[1] * 100, scores_test[0], scores_test[1] * 100]\n",
    "        subject_id.append(group.iloc[test[0]])\n",
    "        # Clear session\n",
    "        K.clear_session()\n",
    "        # Update counter\n",
    "        i += 1\n",
    "        \n",
    "    return pd.DataFrame(cvscores, index = subject_id, columns=['Train_loss', 'Train_acc','Test_loss', 'Test_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_imgs_df = pd.read_csv('driver_imgs_list/driver_imgs_list.csv')\n",
    "driver_imgs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_imgs_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = (driver_imgs_df.classname).value_counts()\n",
    "PlotClassFrequency(class_counts)\n",
    "DescribeImageData(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_counts = (driver_imgs_df.subject).value_counts()\n",
    "plt.figure(figsize=(15,4))\n",
    "plt.bar(subject_counts.index,subject_counts)\n",
    "plt.xlabel('subject')\n",
    "plt.ylabel('count')\n",
    "plt.title('Number of Images per Subject')\n",
    "plt.show()\n",
    "DescribeImageData(subject_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull(driver_imgs_df).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "myarray = np.random.permutation(driver_imgs_df)\n",
    "driver_imgs_df = pd.DataFrame(data = myarray, columns=['subject', 'classname', 'img'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'c0': 0, 'c1': 1, 'c2': 2, 'c3': 3, 'c4': 4, 'c5': 5, 'c6': 6, 'c7': 7, 'c8': 8, 'c9': 9}\n",
    "driver_imgs_df.classname = driver_imgs_df.classname.map(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CreateImgArray(64, 64, 3, driver_imgs_df, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = np.load('X_train_64_64.npy')\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.load('Y_train_64_64.npy')\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotClassFrequency(pd.DataFrame(Y)[0].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = Rescale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PrintImage(X_scaled, 2, Y = Y.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, stage, block, init):\n",
    "    \"\"\"\n",
    "    Implementation of the identity block as defined in Figure 3\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value. You'll need this later to add back to the main path. \n",
    "    X_shortcut = X\n",
    "    \n",
    "    # First component of main path\n",
    "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = init)(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Second component of main path (≈3 lines)\n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = init)(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path (≈2 lines)\n",
    "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = init)(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = Add()([X,X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, stage, block, init, s = 2):\n",
    "    \"\"\"\n",
    "    Implementation of the convolutional block as defined in Figure 4\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "    s -- Integer, specifying the stride to be used\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "\n",
    "    ##### MAIN PATH #####\n",
    "    # First component of main path \n",
    "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', kernel_initializer = init)(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Second component of main path (≈3 lines)\n",
    "    X = Conv2D(F2, (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = init)(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path (≈2 lines)\n",
    "    X = Conv2D(F3, (1, 1), strides = (1,1), name = conv_name_base + '2c', kernel_initializer = init)(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "    ##### SHORTCUT PATH #### (≈2 lines)\n",
    "    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1', kernel_initializer = init)(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = Add()([X,X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(input_shape = (64, 64, 3), classes = 10, init = glorot_uniform(seed=0)):\n",
    "    \"\"\"\n",
    "    Implementation of the popular ResNet50 the following architecture:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
    "\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    \n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    \n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = init)(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1, init = init)\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b', init = init)\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c', init = init)\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Stage 3 (≈4 lines)\n",
    "    X = convolutional_block(X, f = 3, filters = [128,128,512], stage = 3, block='a', s = 2, init = init)\n",
    "    X = identity_block(X, 3, [128,128,512], stage=3, block='b', init = init)\n",
    "    X = identity_block(X, 3, [128,128,512], stage=3, block='c', init = init)\n",
    "    X = identity_block(X, 3, [128,128,512], stage=3, block='d', init = init)\n",
    "\n",
    "    # Stage 4 (≈6 lines)\n",
    "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2, init = init)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b', init = init)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c', init = init)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d', init = init)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e', init = init)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f', init = init)\n",
    "\n",
    "    # Stage 5 (≈3 lines)\n",
    "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2, init = init)\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b', init = init)\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c', init = init)\n",
    "\n",
    "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
    "    X = AveragePooling2D(pool_size=(2, 2), name = 'avg_pool')(X)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = init)(X)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize image vectors\n",
    "X_train = X/255\n",
    "\n",
    "# Convert training and test labels to one hot matrices\n",
    "#Y = convert_to_one_hot(Y.astype(int), 10).T\n",
    "Y_train = np.expand_dims(Y.astype(int), -1)\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = LOGO(X_train, Y_train, group = driver_imgs_df['subject'],\n",
    "              model_name = ResNet50, input_shape = (64, 64, 3), classes = 10, \n",
    "              init = glorot_uniform(seed=0), optimizer = 'adam', metrics = 'accuracy',\n",
    "              epochs = 2, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,4))\n",
    "plt.bar(scores.index, scores.loc[:,'Test_acc'].sort_values(ascending=False))\n",
    "plt.yticks(np.arange(0, 110, 10.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train acc: {:.2f}. Dev. acc: {:.2f}\".format(scores['Train_acc'].mean(), scores['Test_acc'].mean()))\n",
    "print(\"Train loss: {:.2f}. Dev. loss: {:.2f}\".format(scores['Train_loss'].mean(), scores['Test_loss'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = LOGO(X_train, Y_train, group = driver_imgs_df['subject'],\n",
    "              model_name = ResNet50, input_shape = (64, 64, 3), classes = 10, \n",
    "              init = glorot_uniform(seed=0), optimizer = 'adam', metrics = 'accuracy',\n",
    "              epochs = 5, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train acc: {:.2f}. Dev. acc: {:.2f}\".format(scores['Train_acc'].mean(), scores['Test_acc'].mean()))\n",
    "print(\"Train loss: {:.2f}. Dev. loss: {:.2f}\".format(scores['Train_loss'].mean(), scores['Test_loss'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = LOGO(X_train, Y_train, group = driver_imgs_df['subject'],\n",
    "              model_name = ResNet50, input_shape = (64, 64, 3), classes = 10, \n",
    "              init = glorot_uniform(seed=0), optimizer = 'adam', metrics = 'accuracy',\n",
    "              epochs = 10, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train acc: {:.2f}. Dev. acc: {:.2f}\".format(scores['Train_acc'].mean(), scores['Test_acc'].mean()))\n",
    "print(\"Train loss: {:.2f}. Dev. loss: {:.2f}\".format(scores['Train_loss'].mean(), scores['Test_loss'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(input_shape = (64, 64, 3), classes = 10)\n",
    "model.compile(optimizer = 'adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, epochs = 10, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, 'e10.h5');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('e10.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_imgs_df = pd.read_csv('test_file_names.csv')\n",
    "holdout_imgs_df.rename(columns={\"imagename\": \"img\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CreateImgArray(64, 64, 3, holdout_imgs_df, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_holdout = np.load('X_test_64_64.npy')\n",
    "X_holdout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = model.predict(X_holdout, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"test_results.csv\", probabilities, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_holdout_scaled = Rescale(X_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 50000\n",
    "PrintImage(X_holdout_scaled, index = index, Y = probabilities)\n",
    "print('y_pred = ' + str(probabilities[index].argmax()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
